[00:00:00] Pre-processing files (0 Mo)              ░░░░░░░░                  0%
[00:00:00] Pre-processing files (0 Mo)              ████████                100%
[00:00:00] Tokenize words                           ████████ 0        /        0
[00:00:00] Tokenize words                           ████████ 5247     /     5247

[00:00:00] Count pairs                              ████████ 5247     /     5247

[00:00:00] Compute merges                           ░░░░░░░░ 2100     /    30000
[00:00:00] Compute merges                           ████████ 4704     /     4704

[00:00:00] Pre-processing files (0 Mo)              ░░░░░░░░                  0%
[00:00:00] Pre-processing files (0 Mo)              ████████                100%
[00:00:00] Tokenize words                           ████████ 0        /        0
[00:00:00] Tokenize words                           ████████ 1938     /     1938

[00:00:00] Count pairs                              ████████ 1938     /     1938

[00:00:00] Compute merges                           ████████ 2040     /     2040

[00:00:00] Pre-processing files (0 Mo)              ░░░░░░░░                  0%
[00:00:00] Pre-processing files (0 Mo)              ████████                100%
[00:00:00] Tokenize words                           ████████ 0        /        0
[00:00:00] Tokenize words                           ████████ 3343     /     3343

[00:00:00] Count pairs                              ████████ 3343     /     3343

[00:00:00] Compute merges                           ████████ 2866     /     2866

1783
2021-04-11 14:30:16.872160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[Epoch 0 / 100]
Translated example sentence: 
 ['went</w>', 'went</w>', 'snow</w>', 'night</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'information</w>', 'light</w>', 'information</w>', 'unlikely</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>', 'light</w>']
train loss =  5.3000135527716745
valid loss =  4.383569240570068
inf
=> Saving checkpoint
[Epoch 1 / 100]
Translated example sentence: 
 ['i</w>', "'</w>", "'</w>", '.</w>', '<eos>']
train loss =  4.4344093269772
valid loss =  3.963923348320855
4.383569240570068
=> Saving checkpoint
[Epoch 2 / 100]
Translated example sentence: 
 ['i</w>', "'</w>", 's</w>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.</w>', '<eos>']
train loss =  4.08309334119161
valid loss =  3.789662652545505
3.963923348320855
=> Saving checkpoint
[Epoch 3 / 100]
Translated example sentence: 
 ['i</w>', "'</w>", 's</w>', 'a</w>', '<unk>', '<unk>', '.</w>', '<eos>']
train loss =  3.8075660705566405
valid loss =  3.6332094139522977
3.789662652545505
=> Saving checkpoint
[Epoch 4 / 100]
Translated example sentence: 
 ['i</w>', "'</w>", 's</w>', 'a</w>', '<unk>', '<unk>', '.</w>', '<eos>']
train loss =  3.592296192381117
valid loss =  3.5171204143100314
3.6332094139522977
=> Saving checkpoint
[Epoch 5 / 100]
Translated example sentence: 
 ['i</w>', "'</w>", 's</w>', 'a</w>', '<unk>', '<unk>', '<unk>', '.</w>', '<eos>']
train loss =  3.373858992258708
valid loss =  3.4492764472961426
3.5171204143100314
=> Saving checkpoint
[Epoch 6 / 100]
Translated example sentence: 
 ['i</w>', "'</w>", 'm</w>', 'a</w>', '<unk>', '<unk>', '<unk>', '.</w>', '<eos>']
train loss =  3.198187616136339
valid loss =  3.4224765830569797
3.4492764472961426
=> Saving checkpoint
[Epoch 7 / 100]
Translated example sentence: 
 ['you</w>', 'can</w>', "'</w>", 't</w>', 'have</w>', 'to</w>', 'be</w>', 'a</w>', '<unk>', '.</w>', '<eos>']
train loss =  3.0262139956156413
valid loss =  3.3694028854370117
3.4224765830569797
=> Saving checkpoint
[Epoch 8 / 100]
Translated example sentence: 
 ['i</w>', "'</w>", 'm</w>', 'not</w>', 'a</w>', '<unk>', '<unk>', '.</w>', '<eos>']
train loss =  2.854178015391032
valid loss =  3.3526684972974987
3.3694028854370117
=> Saving checkpoint
[Epoch 9 / 100]
Translated example sentence: 
 ['i</w>', "'</w>", 'm</w>', 'not</w>', 'to</w>', 'see</w>', 'you</w>', "'</w>", 's</w>', '.</w>', '<eos>']
train loss =  2.6927712652418347
valid loss =  3.3219911787245007
3.3526684972974987
=> Saving checkpoint
[Epoch 10 / 100]
Translated example sentence: 
 ['i</w>', "'</w>", 'm</w>', 'not</w>', 'to</w>', 'you</w>', 'a</w>', '<unk>', '.</w>', '<eos>']
train loss =  2.539812215169271
valid loss =  3.336235602696737
3.3219911787245007
[Epoch 11 / 100]
Translated example sentence: 
 ['you</w>', "'</w>", 're</w>', 'not</w>', 'a</w>', '<unk>', '<unk>', '<unk>', '<unk>', '.</w>', '<eos>']
train loss =  2.399107011159261
valid loss =  3.3614003128475614
3.336235602696737
[Epoch 12 / 100]
Translated example sentence: 
 ['the</w>', 'moon</w>', 'is</w>', 'not</w>', 'to</w>', 'see</w>', 'you</w>', "'</w>", 's</w>', '<unk>', '.</w>', '<eos>']
train loss =  2.2616567452748617
valid loss =  3.4170176453060574
3.3614003128475614
[Epoch 13 / 100]
Translated example sentence: 
 ['<unk>', 'you</w>', "'</w>", 't</w>', 'have</w>', 'a</w>', '<unk>', '.</w>', '<eos>']
train loss =  2.1387543280919394
valid loss =  3.3658640914493136
3.4170176453060574
=> Saving checkpoint
[Epoch 14 / 100]
Translated example sentence: 
 ['you</w>', "'</w>", 're</w>', 'not</w>', 'a</w>', '<unk>', '<unk>', '.</w>', '<eos>']
train loss =  2.015532890955607
valid loss =  3.3943908479478626
3.3658640914493136
[Epoch 15 / 100]
Translated example sentence: 
 ['i</w>', "'</w>", 've</w>', 'been</w>', 'to</w>', 'see</w>', 'you</w>', "'</w>", 'll</w>', '.</w>', '<eos>']
train loss =  1.8840890261862013
valid loss =  3.3737001419067383
3.3943908479478626
=> Saving checkpoint
[Epoch 16 / 100]
Translated example sentence: 
 ['i</w>', "'</w>", 've</w>', 'been</w>', 'to</w>', 'see</w>', 'you</w>', "'</w>", 're</w>', '<unk>', '.</w>', '<eos>']
train loss =  1.7573391358057657
valid loss =  3.3489399751027427
3.3737001419067383
=> Saving checkpoint
[Epoch 17 / 100]
Translated example sentence: 
 ['<unk>', 'is</w>', 'a</w>', '<unk>', '<unk>', '<unk>', 'in</w>', 'the</w>', '<unk>', 'on', '<unk>', 'in</w>', 'the</w>', '<unk>', '.</w>', '<eos>']
train loss =  1.670328712463379
valid loss =  3.3681334124671087
3.3489399751027427
[Epoch 18 / 100]
Translated example sentence: 
 ['it</w>', "'</w>", 's</w>', 'very</w>', 'high</w>', '<unk>', 'on', 'ight</w>', '.</w>', '<eos>']
train loss =  1.5274497164620293
valid loss =  3.450531323750814
3.3681334124671087
[Epoch 19 / 100]
Translated example sentence: 
 ['it</w>', "'</w>", 's</w>', 'very</w>', 'very</w>', '<unk>', 't', 'on', 'ight</w>', '.</w>', '<eos>']
train loss =  1.4153370208210416
valid loss =  3.484787623087565
3.450531323750814
[Epoch 20 / 100]
Translated example sentence: 
 ['it</w>', "'</w>", 's</w>', 'very</w>', '<unk>', 'on', 'lo', 'new</w>', '.</w>', '<eos>']
Epoch    21: reducing learning rate of group 0 to 3.0000e-05.
train loss =  1.3148228049278259
valid loss =  3.524090396033393
3.484787623087565
overfitting
=> Loading checkpoint
Bleu score 5.12