{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbPXvjpDbBYF"
      },
      "source": [
        "Download the dataset you want from http://www.manythings.org/anki/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiQuc91FYgKP"
      },
      "source": [
        "!git clone https://github.com/Frank-Hebert/transformer_nmt.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9zRZQWhrG7P",
        "outputId": "eefb5108-6d84-4d56-9369-43ad340c0d0e"
      },
      "source": [
        "%cd /content/transformer_nmt/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformer_nmt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbZhQ7sJbL72"
      },
      "source": [
        "Read the dataset and split the languages into 2 different text files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM7-GOJcq3G4"
      },
      "source": [
        "import pandas as pd\n",
        "lt_en = pd.read_csv('./data/lit.txt', delimiter='\\t', header=None).iloc[:,:2].to_numpy(dtype=None, copy=False)\n",
        "np.savetxt('english_lt.txt', lt_en[:,0],fmt='%s')\n",
        "np.savetxt('lithuanian.txt', lt_en[:,1],fmt='%s')"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}