[00:00:00] english_fr.txt                           ░░░░░░░ 0B       /   5.54MB
[00:00:00] english_fr.txt                           ░░░░░░░ 592.00KB /   5.54MB
[00:00:00] french.txt                               ░░░░░░░ 568.00KB /   6.71MB
[00:00:00] english_lt.txt                           ░░░░░░░ 0B       /  59.48KB
[00:00:00] lithuanian.txt                           ░░░░░░░ 0B       /  61.70KB
[00:00:00] english_fr.txt                           █░░░░░░ 1.26MB   /   5.54MB
[00:00:00] french.txt                               █░░░░░░ 1.23MB   /   6.71MB
[00:00:00] english_lt.txt                           ░░░░░░░ 0B       /  59.48KB
[00:00:00] lithuanian.txt                           ░░░░░░░ 0B       /  61.70KB
[00:00:00] english_fr.txt                           ██░░░░░ 1.95MB   /   5.54MB
[00:00:00] french.txt                               ██░░░░░ 1.95MB   /   6.71MB
[00:00:00] english_lt.txt                           ░░░░░░░ 0B       /  59.48KB
[00:00:00] lithuanian.txt                           ░░░░░░░ 0B       /  61.70KB
[00:00:00] english_fr.txt                           ███░░░░ 2.58MB   /   5.54MB
[00:00:00] french.txt                               ██░░░░░ 2.61MB   /   6.71MB
[00:00:00] english_lt.txt                           ░░░░░░░ 0B       /  59.48KB
[00:00:00] lithuanian.txt                           ░░░░░░░ 0B       /  61.70KB
[00:00:00] english_fr.txt                           ████░░░ 3.27MB   /   5.54MB
[00:00:00] french.txt                               ███░░░░ 3.31MB   /   6.71MB
[00:00:00] english_lt.txt                           ░░░░░░░ 0B       /  59.48KB
[00:00:00] lithuanian.txt                           ░░░░░░░ 0B       /  61.70KB
[00:00:00] english_fr.txt                           ████░░░ 3.91MB   /   5.54MB
[00:00:00] french.txt                               ████░░░ 4.05MB   /   6.71MB
[00:00:00] english_lt.txt                           ░░░░░░░ 0B       /  59.48KB
[00:00:00] lithuanian.txt                           ░░░░░░░ 0B       /  61.70KB
[00:00:00] english_fr.txt                           █████░░ 4.66MB   /   5.54MB
[00:00:00] french.txt                               █████░░ 4.80MB   /   6.71MB
[00:00:00] english_lt.txt                           ░░░░░░░ 0B       /  59.48KB
[00:00:00] lithuanian.txt                           ░░░░░░░ 0B       /  61.70KB
[00:00:00] english_fr.txt                           ██████░ 5.42MB   /   5.54MB
[00:00:00] french.txt                               █████░░ 5.55MB   /   6.71MB
[00:00:00] english_lt.txt                           ░░░░░░░ 0B       /  59.48KB
[00:00:00] lithuanian.txt                           ░░░░░░░ 0B       /  61.70KB
[00:00:00] english_fr.txt                           ███████ 5.54MB   /   5.54MB
[00:00:00] french.txt                               █████░░ 5.66MB   /   6.71MB
[00:00:00] english_lt.txt                           ░░░░░░░ 0B       /  59.48KB
[00:00:00] lithuanian.txt                           ░░░░░░░ 0B       /  61.70KB
[00:00:00] english_fr.txt                           ███████ 5.54MB   /   5.54MB
[00:00:00] french.txt                               █████░░ 5.74MB   /   6.71MB
[00:00:00] english_lt.txt                           ███████ 59.48KB  /  59.48KB
[00:00:00] lithuanian.txt                           ░░░░░░░ 0B       /  61.70KB
[00:00:00] english_fr.txt                           ███████ 5.54MB   /   5.54MB
[00:00:00] french.txt                               ██████░ 5.83MB   /   6.71MB
[00:00:00] english_lt.txt                           ███████ 59.48KB  /  59.48KB
[00:00:00] lithuanian.txt                           ███████ 61.70KB  /  61.70KB
[00:00:00] english_fr.txt                           ███████ 5.54MB   /   5.54MB
[00:00:00] french.txt                               ███████ 6.71MB   /   6.71MB
[00:00:00] english_lt.txt                           ███████ 59.48KB  /  59.48KB
[00:00:00] lithuanian.txt                           ███████ 61.70KB  /  61.70KB
[00:00:00] Tokenize words                           ███████ 0        /        0
[00:00:00] Tokenize words                           ░░░░░░░ 5524     /    75892
[00:00:00] Tokenize words                           ░░░░░░░ 10368    /    75892
[00:00:00] Tokenize words                           █░░░░░░ 15792    /    75892
[00:00:00] Tokenize words                           █░░░░░░ 21039    /    75892
[00:00:00] Tokenize words                           ██░░░░░ 25640    /    75892
[00:00:00] Tokenize words                           ██░░░░░ 31120    /    75892
[00:00:00] Tokenize words                           ███░░░░ 36637    /    75892
[00:00:00] Tokenize words                           ███░░░░ 42041    /    75892
[00:00:00] Tokenize words                           ████░░░ 47704    /    75892
[00:00:00] Tokenize words                           ████░░░ 53431    /    75892
[00:00:00] Tokenize words                           █████░░ 59156    /    75892
[00:00:00] Tokenize words                           █████░░ 64830    /    75892
[00:00:00] Tokenize words                           ██████░ 69697    /    75892
[00:00:00] Tokenize words                           ██████░ 75341    /    75892
[00:00:00] Tokenize words                           ███████ 75892    /    75892

[00:00:00] Count pairs                              ███████ 75892    /    75892
[00:00:00] Count pairs                              ███████ 75892    /    75892
[00:00:00] Count pairs                              ███████ 75892    /    75892
[00:00:00] Count pairs                              ███████ 75892    /    75892
[00:00:00] Count pairs                              ███░░░░ 43000    /    75892
[00:00:00] Count pairs                              ███████ 75892    /    75892
[00:00:00] Count pairs                              ███████ 75892    /    75892

[00:00:00] Compute merges                           ███████ 75892    /    75892
[00:00:00] Compute merges                           ███████ 75892    /    30000
[00:00:00] Compute merges                           ███████ 75892    /    30000
[00:00:00] Compute merges                           ███████ 75892    /    30000
[00:00:00] Compute merges                           ░░░░░░░ 7        /    30000
[00:00:00] Compute merges                           ░░░░░░░ 30       /    30000
[00:00:00] Compute merges                           ░░░░░░░ 60       /    30000
[00:00:00] Compute merges                           ░░░░░░░ 115      /    30000
[00:00:00] Compute merges                           ░░░░░░░ 202      /    30000
[00:00:00] Compute merges                           ░░░░░░░ 342      /    30000
[00:00:00] Compute merges                           ░░░░░░░ 552      /    30000
[00:00:00] Compute merges                           ░░░░░░░ 801      /    30000
[00:00:00] Compute merges                           ░░░░░░░ 1116     /    30000
[00:00:00] Compute merges                           ░░░░░░░ 1459     /    30000
[00:00:00] Compute merges                           ░░░░░░░ 1868     /    30000
[00:00:00] Compute merges                           ░░░░░░░ 2352     /    30000
[00:00:00] Compute merges                           ░░░░░░░ 2781     /    30000
[00:00:00] Compute merges                           ░░░░░░░ 3328     /    30000
[00:00:00] Compute merges                           ░░░░░░░ 3905     /    30000
[00:00:01] Compute merges                           █░░░░░░ 4533     /    30000
[00:00:01] Compute merges                           █░░░░░░ 5218     /    30000
[00:00:01] Compute merges                           █░░░░░░ 5813     /    30000
[00:00:01] Compute merges                           █░░░░░░ 6443     /    30000
[00:00:01] Compute merges                           █░░░░░░ 7218     /    30000
[00:00:01] Compute merges                           █░░░░░░ 7896     /    30000
[00:00:01] Compute merges                           ██░░░░░ 8676     /    30000
[00:00:01] Compute merges                           ██░░░░░ 9383     /    30000
[00:00:01] Compute merges                           ██░░░░░ 10158    /    30000
[00:00:01] Compute merges                           ██░░░░░ 10869    /    30000
[00:00:01] Compute merges                           ██░░░░░ 11749    /    30000
[00:00:01] Compute merges                           ██░░░░░ 12648    /    30000
[00:00:01] Compute merges                           ███░░░░ 13384    /    30000
[00:00:01] Compute merges                           ███░░░░ 14217    /    30000
[00:00:01] Compute merges                           ███░░░░ 15056    /    30000
[00:00:02] Compute merges                           ███░░░░ 15982    /    30000
[00:00:02] Compute merges                           ███░░░░ 16918    /    30000
[00:00:02] Compute merges                           ████░░░ 17837    /    30000
[00:00:02] Compute merges                           ████░░░ 18691    /    30000
[00:00:02] Compute merges                           ████░░░ 19667    /    30000
[00:00:02] Compute merges                           ████░░░ 20559    /    30000
[00:00:02] Compute merges                           █████░░ 21511    /    30000
[00:00:02] Compute merges                           █████░░ 22363    /    30000
[00:00:02] Compute merges                           █████░░ 23316    /    30000
[00:00:02] Compute merges                           █████░░ 24432    /    30000
[00:00:02] Compute merges                           █████░░ 25242    /    30000
[00:00:02] Compute merges                           ██████░ 26344    /    30000
[00:00:02] Compute merges                           ██████░ 27314    /    30000
[00:00:02] Compute merges                           ██████░ 28476    /    30000
[00:00:02] Compute merges                           ██████░ 29215    /    30000
[00:00:03] Compute merges                           ███████ 29777    /    29777

1783
2021-04-10 18:02:26.590458: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
[Epoch 0 / 100]
Translated example sentence: 
 ['hospital.</w>', 'hospital.</w>', 'question.</w>', 'years</w>', 'hospital.</w>', 'french.</w>', 'hospital.</w>', 'french.</w>', 'two</w>', 'question.</w>', 'french.</w>', 'chance</w>', 'chance</w>', 'chance</w>', 'question.</w>', 'car</w>', 'question.</w>', 'dangerous.</w>', 'question.</w>', 'french.</w>', 'problem.</w>', 'question.</w>', 'french.</w>', 'two</w>', 'question.</w>', 'question.</w>', 'done</w>', 'chance</w>', 'question.</w>', 'done</w>', 'chance</w>', 'chance</w>', 'question.</w>', "they're</w>", 'done</w>', 'about</w>', 'question.</w>', 'hospital.</w>', 'if</w>', 'chance</w>', 'chance</w>', 'chance</w>', 'chance</w>', 'question.</w>', 'question.</w>', 'hospital.</w>', 'two</w>', 'question.</w>', 'question.</w>', 'proposal.</w>']
train loss =  5.109765158759223
valid loss =  4.08106795946757
inf
=> Saving checkpoint
[Epoch 1 / 100]
Translated example sentence: 
 ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']
train loss =  4.442488569683499
valid loss =  3.684549676047431
4.08106795946757
=> Saving checkpoint
[Epoch 2 / 100]
Translated example sentence: 
 ['i</w>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  4.082481114069621
valid loss =  3.471551603741116
3.684549676047431
=> Saving checkpoint
[Epoch 3 / 100]
Translated example sentence: 
 ['you</w>', 'you</w>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  3.7648160245683457
valid loss =  3.3823578092787
3.471551603741116
=> Saving checkpoint
[Epoch 4 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  3.528905158572727
valid loss =  3.2858475049336753
3.3823578092787
=> Saving checkpoint
[Epoch 5 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  3.2989578353034124
valid loss =  3.1403921445210776
3.2858475049336753
=> Saving checkpoint
[Epoch 6 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  3.0949539661407472
valid loss =  3.296574433644613
3.1403921445210776
[Epoch 7 / 100]
Translated example sentence: 
 ['we</w>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  2.895263687769572
valid loss =  3.061056481467353
3.296574433644613
=> Saving checkpoint
[Epoch 8 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  2.7125718381669786
valid loss =  3.154877954059177
3.061056481467353
[Epoch 9 / 100]
Translated example sentence: 
 ['you</w>', 'need</w>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  2.522551753785875
valid loss =  3.141605271233453
3.154877954059177
=> Saving checkpoint
[Epoch 10 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  2.364029206169976
valid loss =  3.04477416144477
3.141605271233453
=> Saving checkpoint
[Epoch 11 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  2.208740660879347
valid loss =  3.08391973707411
3.04477416144477
[Epoch 12 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', '<unk>', '<unk>', 'in</w>', 'the</w>', '<unk>', '<eos>']
train loss =  2.0535170157750446
valid loss =  3.0695305930243597
3.08391973707411
=> Saving checkpoint
[Epoch 13 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', '<unk>', '<unk>', '<unk>', 'in</w>', 'the</w>', '<unk>', '<eos>']
train loss =  1.921356995900472
valid loss =  3.0885364214579263
3.0695305930243597
[Epoch 14 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', '<unk>', 'by</w>', 'the</w>', '<unk>', '<unk>', '<eos>']
train loss =  1.7836634715398152
valid loss =  3.088490989473131
3.0885364214579263
=> Saving checkpoint
[Epoch 15 / 100]
Translated example sentence: 
 ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  1.6557091924879286
valid loss =  3.1207870642344155
3.088490989473131
[Epoch 16 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', 'in</w>', 'the</w>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  1.546816595395406
valid loss =  3.089276671409607
3.1207870642344155
=> Saving checkpoint
[Epoch 17 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', '<unk>', 'by</w>', 'you</w>', '<unk>', '<eos>']
train loss =  1.4162873612509834
valid loss =  3.1430363919999866
3.089276671409607
[Epoch 18 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', 'in</w>', '<unk>', '<unk>', '<eos>']
train loss =  1.3115689211421542
valid loss =  3.2955381075541177
3.1430363919999866
[Epoch 19 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', 'in</w>', '<unk>', '<unk>', '<eos>']
train loss =  1.2126522541046143
valid loss =  3.1574716567993164
3.2955381075541177
=> Saving checkpoint
[Epoch 20 / 100]
Translated example sentence: 
 ['you</w>', 'need</w>', 'to</w>', '<unk>', '<unk>', '<unk>', '<eos>']
train loss =  1.1326474203003778
valid loss =  3.213308652242025
3.1574716567993164
[Epoch 21 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', 'in</w>', '<unk>', '<unk>', '<eos>']
Epoch    22: reducing learning rate of group 0 to 3.0000e-05.
train loss =  1.0130779438548618
valid loss =  3.208309226565891
3.213308652242025
=> Saving checkpoint
[Epoch 22 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', 'in</w>', '<unk>', '<unk>', '<eos>']
train loss =  0.8826493408944872
valid loss =  3.2111584610409207
3.208309226565891
[Epoch 23 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', 'very</w>', '<unk>', '<unk>', '<eos>']
train loss =  0.8369366486867269
valid loss =  3.253120952182346
3.2111584610409207
[Epoch 24 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', 'in</w>', '<unk>', '<unk>', '<eos>']
train loss =  0.8211468093925052
valid loss =  3.2410568396250405
3.253120952182346
=> Saving checkpoint
[Epoch 25 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', 'in</w>', '<unk>', '<unk>', '<eos>']
train loss =  0.7969822141859266
valid loss =  3.2495396931966147
3.2410568396250405
[Epoch 26 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', 'in</w>', '<unk>', '<unk>', '<eos>']
train loss =  0.7956199288368225
valid loss =  3.270222822825114
3.2495396931966147
[Epoch 27 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', 'in</w>', '<unk>', '<unk>', '<eos>']
train loss =  0.7716059830453661
valid loss =  3.2848130067189536
3.270222822825114
[Epoch 28 / 100]
Translated example sentence: 
 ['you</w>', '<unk>', 'in</w>', '<unk>', '<unk>', '<eos>']
train loss =  0.7573653565512763
valid loss =  3.2914435863494873
3.2848130067189536
overfitting
=> Loading checkpoint
Bleu score 47.86